# Sign-Language-Translator-IOS-ML

IOS app that uses TensorFlow to create an object detection model that recognizes different objects in the camera feed. If the
model can detect a hand it screenshots the hand and passes this image to a CoreML model that recognizes the character that was
signed in American Sign Langauge and then it is displayed on screen and using text to speech, repeated back to the user. Another
functionality is the speech to text which allows for 2-way communication for people with hearing disabilities aswell as those without.

XCode Project requires all build materials to run, however that is too large to upload to github. Message me if you would like to use this project.
